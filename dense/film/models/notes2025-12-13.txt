# ------------------------------------
#
#                Model 3
#
# ------------------------------------

• 40 to 80 dataset
• kinda shit?
• still displays proportionately better behaviour at lower angles
• if evaluated on 22 to 90 dataset, will spike massively at 40.

# ------------------------------------
#
#                Model 5
#
# ------------------------------------

• 22 to 90 dataset
• definitely still shit
• when evaluated on unseen data, produces same result to on trained data. this indicates good
generalisation during training?


# ------------------------------------
#
#                Model 6
#
# ------------------------------------

• broken 22 to 90 dataset 
• 80% accuracy
• circular distribution


# ------------------------------------
#
#                Model 8
#
# ------------------------------------

• Fixed bottlenecking